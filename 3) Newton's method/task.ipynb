{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрите по вариантам (v3) следующие задачи оптимизации:\n",
    "* Log-optimal investment strategy without the constraint $x≥0$ ([ex. 4.60, p. 209](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf#page=223) and [10.14, p. 559](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf#page=573));\n",
    "* Equality constrained analytic centering ([p. 548](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf#page=562));\n",
    "\n",
    "$\\to$ Equality constrained entropy maximization ([10.9, p. 558](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf#page=572));\n",
    "* Minimizing a separable function subject to an equality constraint, $f_i(x_i) = x_i^4$, $i∈\\{1, ..., n\\}$ ([ex. 5.4, p. 248](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf#page=262));\n",
    "* Optimal allocation with resource constraint, $f_i(x_i) = A_ie^{x_i} , A_i > 0$, $i ∈\\{1, ..., n\\}$ ([ex. 10.1, p. 523](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf#page=537))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дана следующая задача: $f(x) = \\sum_{i=1}^{n}x_i log_e x_i = \\sum_{i=1}^{n}x_i ln(x_i) \\to min$.\n",
    "\n",
    "При ограничении: $Ax=b$.\n",
    "\n",
    "Где $x ∈ R_{++}^n$, $A ∈ R^{m*n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Исследуйте задачу на выпуклость. Запишите необходимые условия минимума и двойственную задачу. \n",
    "2) Для каждого значения размерности $n ∈ \\{10, 20, ..., 100\\}$ сгенерируйте $N = 100$ тестовых примеров (необходимо проверять, чтобы целевая функция на допустимом множестве была ограни-\n",
    "чена снизу). В каждом случае найдите глобальный минимум, $x^∗ ∈R^n$, с помощью CVX.\n",
    "3) Для каждого значения $n ∈ \\{10, 20, ..., 100\\}$ и для каждого тестового примера сгенерируйте 100 начальных точек. Для заданной точности $ε = 0.01$ по значению функции решите задачу с помощью прямого и двойственного метода Ньютона (стандартный метод Ньютона для решения двойственной задачи). Приведите необходимые аналитические вычисления.\n",
    "4) В качестве результата работы метода:\n",
    "    * Для каждого метода и значений $n ∈\\{10, 20, ..., 100\\}$ среднее время работы метода и среднее число итераций (усреднение проводится по всем начальным точкам и по всем тестовым примерам). Сколько арифметических операций требуется для выполнения одной итерации метода?\n",
    "    * Для одного тестового примера при $n = 10$ и нескольких различных начальных точек постройте зависимость точности по значению функции от числа итераций. Сравните полученные результаты для прямого и двойственного метода."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Настройки/Импорты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Версии важных модулей:\n",
    "* cvxpy==1.4.3\n",
    "* numpy==1.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp # солвер для задач\n",
    "import numpy as np # для работы с массивами\n",
    "\n",
    "import time # для отслеживания времени выполнения\n",
    "from tqdm import tqdm # для отслеживания прогресса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.arange(10, 101, 10) # возможные значения n (число переменных в задаче ~ размерность пространства) от 10 до 100 включительно\n",
    "# m = (n/2).astype(np.int32) # первая размерность матрицы A (должна быть меньше n, например, в два раза меньше n)\n",
    "N = 100 # число тестовых примеров для каждого значения n\n",
    "P = 100 # число начальных точек для каждого примера N\n",
    "ε = 0.01 # необходимая точность\n",
    "\n",
    "DIM = 10 # интересующая нас размерность пространства, на которой будут проходить тесты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Вспомогательные функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевая функция $f(x) = \\sum_{i=1}^{n}x_i ln(x_i) \\to min$, где $x ∈ R_{++}^n$, $A ∈ R^{m*n}$. <br>\n",
    "Что аналогично матричному виду: \n",
    "* $x^T ln(x) \\to min$.\n",
    "\n",
    "Её ограничение: \n",
    "* $Ax=b$.\n",
    "\n",
    "Производная: \n",
    "* $∇f(x) = ln(x) + 1$, где под 1 понимается вектор-столбец размерности $(n, 1)$.\n",
    "\n",
    "Гессиан: \n",
    "* $\\frac{d^2f(x)}{dx^2} = \\begin{pmatrix} \\frac{1}{x_1} & 0 & ... & 0 \\\\ ... & ... & ... & ... \\\\ 0 & ... & 0 & \\frac{1}{x_n} \\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_primal(x: np.array) -> np.float32:\n",
    "    \"\"\"\n",
    "    Функция из задачи.\\n\n",
    "    Parameters:\n",
    "        * x: текущие значения x (в виде столбца)\\n\n",
    "    Returns:\n",
    "        * np.float32: значение функции в точке x\n",
    "    \"\"\"\n",
    "    res = x.T @ np.emath.logn(np.e, x) # dot-product вектора x на значение его логарифма\n",
    "    return res[0] # значение функции ([0] — из-за вложенности)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_primal_grad(x: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Производная функции из задачи.\\n\n",
    "    Parameters:\n",
    "        * x: текущие значения x (в виде столбца)\\n\n",
    "    Returns:\n",
    "        * np.array: вектор-столбец градиента функции в точке x\n",
    "    \"\"\"\n",
    "    return np.emath.logn(np.e, x) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_primal_hessian(x: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Гессиан (матрица вторых производных) функции из задачи.\\n\n",
    "    Parameters:\n",
    "        * x: текущие значения x (в виде столбца)\\n\n",
    "    Returns:\n",
    "        * np.array: матрица вторых производных функции в точке x\n",
    "    \"\"\"\n",
    "    return np.diag(1/x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constraints_primal(x: np.array, A: np.array, b: np.array) -> bool:\n",
    "    \"\"\"\n",
    "    Функция для проверка решения на допустимость.\\n\n",
    "    Parameters:\n",
    "        * x: текущие значения x (в виде вектора-столбца)\n",
    "        * A: матрица A\n",
    "        * b: значение ограничений\\n\n",
    "    Returns:\n",
    "        * bool: True — если решение допустимо, иначе — False\n",
    "    \"\"\"\n",
    "    # return A @ x == b\n",
    "    return np.allclose(A @ x, b)\n",
    "\n",
    "\n",
    "# def constraints_primal(x: np.array, A: np.array) -> bool:\n",
    "#     \"\"\"\n",
    "#     Функция для проверка решения на допустимость.\\n\n",
    "#     Parameters:\n",
    "#         * x: текущие значения x (в виде вектора-столбца)\n",
    "#         * A: матрица A\\n\n",
    "#     Returns:\n",
    "#         * bool: True — если решение допустимо, иначе — False\n",
    "#     \"\"\"\n",
    "#     return A @ x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Исследование задачи на выпуклость. Необходимые условия минимума. Двойственная задача."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная задача считается решаемой тогда и только тогда, когда $rank(A) = p < n$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выпуклость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Определения:**\n",
    "1) Функция $f(x)$ считается ***convex*** (выпуклой вниз), если для $∀x,y ∈ X ⊂ R^n, ∀γ∈$ отрузку $[0, 1]$ выполняется неравенство: $f(γx + (1-γ)y) ≤ γf(x) + (1-γ)f(y)$. Другими словами — функция выпукла, если любая хорда, соединяющая две точки функции, лежит не ниже самой функции. <br>\n",
    "![Определение выпуклой вниз функции](./images/convex.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Функция прошла проверку на выпуклость!\n"
     ]
    }
   ],
   "source": [
    "for i in range(N): # идём по числу тест-кейсов\n",
    "    x, y = np.random.rand(DIM, 1), np.random.rand(DIM, 1) # случайно генерируем точки x и y в пространстве размерности DIM ((DIM, 1) — для вектора-столбца)\n",
    "    γ = np.random.uniform(low=0, high=1) # случайное соотношение x и y (равномерное от 0 до 1)\n",
    "    if not (func_primal(γ*x+(1-γ)*y) <= γ * func_primal(x) + (1-γ) * func_primal(y)): # если условие выпуклости нарушено\n",
    "        raise Exception(\"Условие выпуклости нарушено!\") # выкидываем исключение\n",
    "\n",
    "print(\"Функция прошла проверку на выпуклость!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под ограничением $Ax=b$ понимается пересечение плоскостей (при этом таких плоскостей меньше, чем размерность пространства, $m<n$). Каждая плоскость является выпуклым множеством. Очевидно, что пересечение выпуклых множеств будет выпуклым.\n",
    "\n",
    "![Определение выпуклой вниз функции](./images/constraints_intersection.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Условие минимума."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Необходимое условие минимума функции: если функция $f(x)$ имеет минимум в точке $х = а$, то в этой точке производная либо **равна нулю**, либо **не существует** (равна бесконечности)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Двойственная задача."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим двойственную задачу по аналогии из предыдущей лабораторной работу.\n",
    "\n",
    "Изначально целевая функция имеет вид: $f(x) = \\sum_{i=1}^{n}x_i ln(x_i) = x^T ln(x) \\to min$. <br>\n",
    "А ограничение: $Ax=b$.\n",
    "\n",
    "Тогда её функция Лагранжа $L(x, λ)$ имеет вид: \n",
    "* $L(x, λ) = x^T ln(x) + λ^T(Ax - b)$.\n",
    "\n",
    "Производная функции Лагранжа $\\frac{dL(x, λ)}{dx}$:\n",
    "* $\\frac{dL(x, λ)}{dx} = ln(x) + 1 + A^Tλ = 0$.\n",
    "\n",
    "Выражаем значение $x^*$:\n",
    "* $ln(x^*) + 1 + A^Tλ = 0$\n",
    "* $ln(x^*) = -(1 + A^Tλ)$\n",
    "* $x^* = e^{-(1 + A^Tλ)}$\n",
    "\n",
    "Подставляем полученное значение $x^*$ в $L(x, λ)$:\n",
    "* $g(λ) = (e^{-(1 + A^Tλ)})^T (-(1 + A^Tλ)) + λ^T(Ae^{-(1 + A^Tλ)} - b) = -e^{-(1^T + λ^TA)} (1 + A^Tλ) + λ^T(Ae^{-(1 + A^Tλ)} - b)$\n",
    "\n",
    "Таким образом ***двойственная задача*** выглядит следующим образом:\n",
    "* Целевая функция: $g(λ) = -e^{-(1^T + λ^TA)} (1 + A^Tλ) + λ^T(Ae^{-(1 + A^Tλ)} - b) \\to max$.\n",
    "* Ограничений нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим получившуюся задачу более пристально.\n",
    "\n",
    "Лагранжиан $L(x, λ)$ имеет вид:\n",
    "* $L(x, λ) = \\sum_{i=1}^{n}x_i ln(x_i) + \\sum_{i=1}^{n} \\sum_{j=1}^{m} x_i λ_j A_{ji} - \\sum_{j=1}^{m} λ_j b_j$.\n",
    "\n",
    "Производная функции Лагранжа $\\frac{dL(x, λ)}{dx}$:\n",
    "* $\\frac{dL(x, λ)}{dx} = \\begin{pmatrix} ln(x_i) + 1 + \\sum_{j=1}^{m} λ_j A_{j1} \\\\ ... \\\\ ln(x_n) + 1 + \\sum_{j=1}^{m} λ_j A_{jn} \\end{pmatrix}$.\n",
    "\n",
    "Из неё значение $x^*$ вычисляется как:\n",
    "* $\\frac{dL(x, λ)}{dx} = \\begin{pmatrix} ln(x_i) + 1 + \\sum_{j=1}^{m} λ_j A_{j1} \\\\ ... \\\\ ln(x_n) + 1 + \\sum_{j=1}^{m} λ_j A_{jn} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ ... \\\\ 0 \\end{pmatrix}$\n",
    "* $x^* = \\begin{pmatrix} e^{-(1+\\sum_{j=1}^{m} λ_j A_{j1})} \\\\ ... \\\\ e^{-(1+\\sum_{j=1}^{m} λ_j A_{jn})} \\end{pmatrix}$\n",
    "* $x_i^* = e^{-(1+\\sum_{j=1}^{m} λ_j A_{ji})}$\n",
    "\n",
    "Подставляем значение $x^*$ в $L(x, λ)$:\n",
    "* $g(λ) = \\sum_{i=1}^{n} e^{-(1+\\sum_{j=1}^{m} λ_j A_{ji})} (-(1+\\sum_{j=1}^{m} λ_j A_{ji})) + \\sum_{i=1}^{n} \\sum_{j=1}^{m} e^{-(1+\\sum_{j=1}^{m} λ_j A_{ji})} λ_j A_{ji} - \\sum_{j=1}^{m} λ_j b_j$\n",
    "* $g(λ) = \\sum_{i=1}^{n} e^{-1-\\sum_{j=1}^{m} λ_j A_{ji}} (-1-\\sum_{j=1}^{m} λ_j A_{ji}) + \\sum_{i=1}^{n} \\sum_{j=1}^{m} e^{-1-\\sum_{j=1}^{m} λ_j A_{ji}} λ_j A_{ji} - \\sum_{j=1}^{m} λ_j b_j$\n",
    "* $g(λ) = -\\sum_{i=1}^{n} e^{-1-\\sum_{j=1}^{m} λ_j A_{ji}} - \\sum_{j=1}^{m} λ_j b_j$\n",
    "* $g(λ) = -\\sum_{i=1}^{n} e^{-1-λ^T A_{*i}} - λ^T b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Двойственная задача*** была упрошена до:\n",
    "* Целевая функция: $g(λ) = -\\sum_{i=1}^{n} e^{-1-λ^T A_{*i}} - λ^T b \\to max$.\n",
    "* Ограничений нет."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Производная двойственной функции $g(λ)$ по $λ$ имеет следующий вид:\n",
    "* $\\frac{dg(λ)}{dλ} = \\begin{pmatrix} \\sum_{i=1}^{n} e^{-1-\\sum_{j=1}^{m} λ_j A_{ji}} A_{1i} - b_1 \\\\ ... \\\\ \\sum_{i=1}^{n} e^{-1-\\sum_{j=1}^{m} λ_j A_{ji}} A_{mi} - b_m \\end{pmatrix}$\n",
    "* $∇g(λ) = \\sum_{i=1}^{n} e^{-1-λ^T A_{*i}} A_{*i} - b$\n",
    "\n",
    "А Гессиан:\n",
    "* $\\frac{d^2g(λ)}{dλ^2} = \\begin{pmatrix} -\\sum_{i=1}^{n} e^{-1-\\sum_{j=1}^{m} λ_j A_{ji}} A_{1i} A_{1i} & ... & -\\sum_{i=1}^{n} e^{-1-\\sum_{j=1}^{m} λ_j A_{ji}} A_{1i} A_{mi} \\\\ ... & ... & ... \\\\ -\\sum_{i=1}^{n} e^{-1-\\sum_{j=1}^{m} λ_j A_{ji}} A_{mi} A_{1i} & ... & -\\sum_{i=1}^{n} e^{-1-\\sum_{j=1}^{m} λ_j A_{ji}} A_{mi} A_{mi} \\end{pmatrix}$\n",
    "* $∇^2g(λ) = - \\sum_{i=1}^{n} e^{-1-λ^T A_{*i}} A_{*i} A_{*i}^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_dual(λ: np.array, A: np.array, b: np.array) -> np.float32:\n",
    "    \"\"\"\n",
    "    Двойственная функция (задача) (построена с использованием функции Лагранжа).\\n\n",
    "    Parameters:\n",
    "        * λ: текущие значения λ\n",
    "        * A: матрица A\n",
    "        * b: значение ограничений прямой задачи\\n\n",
    "    Returns:\n",
    "        * np.float32: значение двойственной функции в точке λ\n",
    "    \"\"\"\n",
    "    n = A.shape[1] # число переменных в прямой задаче\n",
    "    #================================= old =================================\n",
    "    # ones = np.ones(shape=(n, 1)) # вектор-столбец единиц\n",
    "    # t_1 = ones + A.T @ λ # значение первого сокращения\n",
    "    # t_2 = ones.T + λ.T @ A # значение второго сокращения\n",
    "    # res = -np.e ** (-t_2) @ t_1 + λ.T @ (A @ np.e ** (-t_1) - b) # считаем двойственную целевую функцию\n",
    "    #--------------------------------- new ---------------------------------\n",
    "    res = - λ.T @ b # считаем двойственную целевую функцию\n",
    "    for i in range(n): # идём по размерности n\n",
    "        res -= np.e ** (-1-λ.T @ A[:, i]) # считаем двойственную целевую функцию\n",
    "    #=======================================================================\n",
    "    return res[0] # значение двойственной функции ([0] — из-за вложенности)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_dual_grad(λ: np.array, A: np.array, b: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Производная двойственной функции из задачи.\\n\n",
    "    Parameters:\n",
    "        * λ: текущие значения λ\n",
    "        * A: матрица A\n",
    "        * b: значение ограничений прямой задачи\\n\n",
    "    Returns:\n",
    "        * np.array: вектор-столбец градиента функции в точке λ\n",
    "    \"\"\"\n",
    "    m, n = A.shape # размерность матрицы А (m - число ограничений в прямой задаче, n - число компонент в прямой задаче)\n",
    "    #================================ slow =================================\n",
    "    # grad = np.zeros((m, 1)) # заготовка под градиент\n",
    "    # for j in range(m): # идём по числу ограничений (числу компонент в двойственной задаче ~ градиенте)\n",
    "    #     grad[j] -= b[j] # вычитаем соответствующее ограничение (число)\n",
    "    #     for i in range(n): # идём по числу переменных в прямой задаче\n",
    "    #         grad[j] += np.e ** (-1 -λ.T @ A[:, i]) * A[j][i] # заполняем вектор градиента\n",
    "    #-------------------------------- fast ---------------------------------\n",
    "    grad = -b # вычитаем соответствующее ограничение (вектор размерности (m, 1))\n",
    "    for i in range(n): # идём по числу переменных в прямой задаче\n",
    "        grad += np.e ** (-1-λ.T @ A[:, i]) * A[:, [i]] # заполняем вектор градиента\n",
    "    #=======================================================================\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_dual_hessian(λ: np.array, A: np.array, b: np.array) -> np.array:\n",
    "    \"\"\"\n",
    "    Гессиан (матрица вторых производных) двойственной функции из задачи.\\n\n",
    "    Parameters:\n",
    "        * λ: текущие значения λ\n",
    "        * A: матрица A\n",
    "        * b: значение ограничений прямой задачи\\n\n",
    "    Returns:\n",
    "        * np.array: матрица вторых производных двойственной функции в точке λ\n",
    "    \"\"\"\n",
    "    m, n = A.shape # размерность матрицы А (m - число ограничений в прямой задаче, n - число компонент в прямой задаче)\n",
    "    hess = np.zeros(shape=(m, m)) # матрица под гессиан\n",
    "    #================================ slow =================================\n",
    "    # for i in range(m): # идём по числу ограничений (числу компонент в двойственной задаче)\n",
    "    #     for j in range(m): # идём по числу ограничений (числу компонент в двойственной задаче)\n",
    "    #         for k in range(n): # идём по числу переменных в прямой задаче\n",
    "    #             hess[i][j] -= np.e**(-1-λ.T @ A[:, [k]]) * A[i][k] * A[j][k] # заполняем матрицу градиента\n",
    "    #-------------------------------- fast ---------------------------------\n",
    "    for k in range(n): # идём по числу переменных в прямой задаче\n",
    "        hess -= np.e**(-1-λ.T @ A[:, [k]]) * A[:, [k]] @ A[:, [k]].T # заполняем матрицу градиента\n",
    "    #=======================================================================\n",
    "    return hess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Генерация и решение тестовых примеров с помощью встроенных методов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получаем истинные ответы от солвера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.70s/it]\n"
     ]
    }
   ],
   "source": [
    "data = {} # словарь под данные для теста\n",
    "\n",
    "for dim in tqdm(n): # идём по возможному числу переменных (размерности пространства)\n",
    "    m = int(dim/2) # первая размерность матрицы A = число ограничений (должна быть меньше n, например, в два раза меньше n)\n",
    "    data[dim] = {i: {} for i in range(N)} # подсловарь под тест-кейсы для рассматриваемой размерности dim (получилась тройная вложенность словаря)\n",
    "    for i in range(N): # идём по числу тест-кейсов\n",
    "        # решаем прямую задачу с помощью солвера\n",
    "        x = cp.Variable(shape=(dim, 1)) # значения переменных\n",
    "        A = np.random.randn(m, dim) # генерируем случайную матрицу A размера (m, dim) из нормального распределения\n",
    "        b = A.dot(np.random.rand(dim, 1)) # генерируем соответствующую матрицу b таким образом, чтобы пересечение всех ограничений было в допустимой области определения функции\n",
    "        objective = cp.Minimize(cp.sum(-cp.entr(x))) # целевая функция (cp.entr в cvx идёт как '-x * lnx' для задачи максимизации, у нас же она на минимум, поэтому домножаем на -1)\n",
    "        # objective = cp.Minimize(cp.sum(x * cp.log(x)/cp.log(2))) # целевая функция\n",
    "        # objective = cp.Minimize(cp.sum(cp.multiply(x, cp.log(x)))) # целевая функция\n",
    "        constraints = [A@x == b] # список накладываемых ограничений\n",
    "        problem = cp.Problem(objective, constraints) # создаём объект решаемой задачи\n",
    "        res = problem.solve(solver=cp.ECOS) # решаем поставленную проблему с помощью solver\n",
    "\n",
    "        data[dim][i][\"A\"] = A # запоминаем матрицу A\n",
    "        data[dim][i][\"b\"] = b # значения ограничений\n",
    "        data[dim][i][\"X opt solver\"] = x.value # оптимальное значение X от встроенного солвера\n",
    "        data[dim][i][\"Result solver\"] = res # ответ от встроенного солвера"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Реализация и тестирование метода Ньютона."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Для прямой задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_primal(x: np.array, A: np.array, b: np.array, res_solver: np.float32, ε: np.float32) -> list:\n",
    "    \"\"\"\n",
    "    Метод Ньютона для подсчёта оптимума прямой задачи.\\n\n",
    "    Parameters:\n",
    "        * x: изначальное значения x\n",
    "        * A: матрица A\n",
    "        * b: значение ограничений прямой задачи\n",
    "        * res_solver: уже полученный ответ от солвера, к которому нужно сойтись\n",
    "        * ε: необходимая точность ответа\\n\n",
    "    Returns:\n",
    "        * list: [оптимальное значение функции, оптимальное значение x, число итераций]\n",
    "    \"\"\"\n",
    "    iterations = 0 # счётчик итераций градиентного спуска\n",
    "    η = 1 # значение шага\n",
    "\n",
    "    res_newton_primal = func_primal(x) # # значение начального решения для рассматриваемой стартовой точки\n",
    "    while abs(res_solver - res_newton_primal) > ε: # пока не сошлись с ответом солвера\n",
    "        # print(iterations, abs(res_solver - res_grad_dual))\n",
    "        H = func_primal_hessian(x) # Гессиан\n",
    "        x = x - η * np.linalg.inv(H) @ func_primal_grad(x) # обновляем значение x (так как задача минимизации, то идём в сторону против градиента)\n",
    "        if not constraints_primal(x, A, b): # если нарушили ограничение ~ вышли из допустимой области\n",
    "            raise Exception(\"Constraint!\")\n",
    "        \n",
    "        res_newton_primal = func_primal(x) # считаем значение функции\n",
    "        \n",
    "        iterations += 1 # увеличиваем общее число итераций на рассматриваемой размерности dim\n",
    "\n",
    "    return [res_newton_primal, x, iterations] # возвращаем [оптимальное значение функции, оптимальное значение x, число итераций]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in tqdm(n): # идём по возможному числу переменных (размерности пространства)\n",
    "    m = int(dim/2) # первая размерность матрицы A = число ограничений (должна быть меньше n, например, в два раза меньше n)\n",
    "    iterations = 0 # всего итераций для решения всех тест-кейсов при всех начальных точках\n",
    "    time_start = time.time() # замеряем время старта рассмотрения размерности dim\n",
    "\n",
    "    for i in range(N): # идём по числу тест-кейсов\n",
    "        A = data[dim][i][\"A\"] # матрица А для тест-кейса\n",
    "        b = data[dim][i][\"b\"] # вектор b для тест-кейса\n",
    "        res_solver = data[dim][i][\"Result solver\"] # результат от солвера для тест-кейса\n",
    "        \n",
    "        for p in tqdm(range(P)): # идём по числу случайных стартовых точек\n",
    "            x = np.random.rand(m, 1) # генерируем случайное значение x\n",
    "            \n",
    "            \n",
    "            iterations += gradient_descent_dual(λ, A, b, η, res_solver, ε)[2] # запоминаем число итераций, что потребовалось градиентному спуску чтобы сойтись с ответом солвера с точностью ε\n",
    "\n",
    "    data[dim][\"Average time grad dual\"] = (time.time() - time_start) / (N * P) # среднее время для размерности dim за (N * p) решённых вариантов задачи\n",
    "    data[dim][\"Average iterations grad dual\"] = iterations / (N * P) # среднее число итерации для размерности dim за (N * p) решённых вариантов задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Для двойственной задачи."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_primal(x: np.array, A: np.array, b: np.array, res_solver: np.float32, ε: np.float32) -> list:\n",
    "    \"\"\"\n",
    "    Метод Ньютона для подсчёта оптимума прямой задачи.\\n\n",
    "    Parameters:\n",
    "        * x: изначальное значения x\n",
    "        * A: матрица A\n",
    "        * b: значение ограничений прямой задачи\n",
    "        * res_solver: уже полученный ответ от солвера, к которому нужно сойтись\n",
    "        * ε: необходимая точность ответа\\n\n",
    "    Returns:\n",
    "        * list: [оптимальное значение функции, оптимальное значение x, число итераций]\n",
    "    \"\"\"\n",
    "    iterations = 0 # счётчик итераций градиентного спуска\n",
    "\n",
    "    res_newton_primal = func_primal(x, A, b) # # значение начального решения для рассматриваемой стартовой точки\n",
    "    while abs(res_solver - res_newton_primal) > ε: # пока не сошлись с ответом солвера\n",
    "        # print(iterations, abs(res_solver - res_grad_dual))\n",
    "        H = func_primal_hessian(x) # Гессиан\n",
    "        x = x - η * np.linalg.inv(H) @ func_primal_grad(x) # обновляем значение x (так как задача минимизации, то идём в сторону против градиента)\n",
    "\n",
    "        res_newton_primal = func_primal(x, A, b) # считаем значение функции\n",
    "        \n",
    "        iterations += 1 # увеличиваем общее число итераций на рассматриваемой размерности dim\n",
    "        η = max(η * 0.999, 0.0001) # слегка уменьшаем шаг, но не меньше 0.0001\n",
    "\n",
    "    return [res_grad_dual, x, iterations] # возвращаем [оптимальное значение функции, оптимальное значение x, число итераций]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dim in tqdm(n): # идём по возможному числу переменных (размерности пространства)\n",
    "    m = int(dim/2) # первая размерность матрицы A = число ограничений (должна быть меньше n, например, в два раза меньше n)\n",
    "    iterations = 0 # всего итераций для решения всех тест-кейсов при всех начальных точках\n",
    "    time_start = time.time() # замеряем время старта рассмотрения размерности dim\n",
    "\n",
    "    for i in range(N): # идём по числу тест-кейсов\n",
    "        A = data[dim][i][\"A\"] # матрица А для тест-кейса\n",
    "        b = data[dim][i][\"b\"] # вектор b для тест-кейса\n",
    "        res_solver = data[dim][i][\"Result solver\"] # результат от солвера для тест-кейса\n",
    "        \n",
    "        for p in tqdm(range(P)): # идём по числу случайных стартовых точек\n",
    "            λ = np.random.rand(m, 1) # генерируем случайное значение λ (np.array двойной вложенности) из равномерного распределения [0, 1), удоавлетворяющее ограничению λ ≥ 0\n",
    "            \n",
    "            iterations += gradient_descent_dual(λ, A, b, η, res_solver, ε)[2] # запоминаем число итераций, что потребовалось градиентному спуску чтобы сойтись с ответом солвера с точностью ε\n",
    "\n",
    "    data[dim][\"Average time grad dual\"] = (time.time() - time_start) / (N * P) # среднее время для размерности dim за (N * p) решённых вариантов задачи\n",
    "    data[dim][\"Average iterations grad dual\"] = iterations / (N * P) # среднее число итерации для размерности dim за (N * p) решённых вариантов задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# тесты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randn(5, 7)\n",
    "b = np.random.randn(5, 1)\n",
    "λ = np.array([[1], [2], [3], [4], [5]])\n",
    "n_ = 7\n",
    "m = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-192.45897038]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# целевая функция\n",
    "res = - λ.T @ b\n",
    "for i in range(n_):\n",
    "    res -= np.e ** (-1-λ.T @ A[:, i])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  53.17588234],\n",
       "       [ 100.16262187],\n",
       "       [ -73.47897787],\n",
       "       [-186.25384149],\n",
       "       [ -64.18775149]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# градиент\n",
    "g_1 = np.zeros((m, 1))\n",
    "\n",
    "# for z in range(m):\n",
    "#     g_1[z] -= b[z]\n",
    "#     for i in range(n_):\n",
    "#         g_1[z] += np.e ** (-1 -λ.T @ A[:, i]) * A[z][i]\n",
    "\n",
    "g_2 = -b\n",
    "for i in range(n_):\n",
    "    g_2 += np.e ** (-1-λ.T @ A[:, i]) * A[:, [i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-182.95186741, -132.59787434,  -73.5569164 ,  179.16688049,\n",
       "          40.11520402],\n",
       "       [-132.59787434, -131.56638256,  -21.26355395,  188.00226026,\n",
       "          49.51070373],\n",
       "       [ -73.5569164 ,  -21.26355395,  -79.92636478,    2.05936129,\n",
       "         -11.90482102],\n",
       "       [ 179.16688049,  188.00226026,    2.05936129, -299.62438678,\n",
       "         -76.03813593],\n",
       "       [  40.11520402,   49.51070373,  -11.90482102,  -76.03813593,\n",
       "         -27.61893633]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# гессиан\n",
    "H_1 = np.zeros(shape=(m, m))\n",
    "# for i in range(m):\n",
    "#     for j in range(m):\n",
    "#         for k in range(n_):\n",
    "#             H_1[i][j] -= np.e**(-1-λ.T @ A[:, [k]]) * A[i][k] * A[j][k]\n",
    "\n",
    "for k in range(n_):\n",
    "    H_1 -= np.e**(-1-λ.T @ A[:, [k]]) * A[:, [k]] @ A[:, [k]].T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cplex",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
